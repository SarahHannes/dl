{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "text-generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Library to fix contractions\n",
        "!pip install contractions"
      ],
      "metadata": {
        "id": "69eZ5UYpYqTM",
        "outputId": "a92482f6-2a32-438d-a785-ceee844caf09",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:02.810319Z",
          "iopub.execute_input": "2022-04-03T14:45:02.810866Z",
          "iopub.status.idle": "2022-04-03T14:45:13.024735Z",
          "shell.execute_reply.started": "2022-04-03T14:45:02.810827Z",
          "shell.execute_reply": "2022-04-03T14:45:13.023921Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting contractions\n  Downloading contractions-0.1.68-py2.py3-none-any.whl (8.1 kB)\nCollecting textsearch>=0.0.21\n  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\nCollecting anyascii\n  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n     |████████████████████████████████| 284 kB 891 kB/s            \n\u001b[?25hCollecting pyahocorasick\n  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n     |████████████████████████████████| 106 kB 12.7 MB/s            \n\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\nSuccessfully installed anyascii-0.3.0 contractions-0.1.68 pyahocorasick-1.4.4 textsearch-0.0.21\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module to get variable name as str\n",
        "!pip3 install varname"
      ],
      "metadata": {
        "id": "vunSd9oJcx7j",
        "outputId": "1fe3e84d-3823-4a87-923f-79500ce94d92",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:13.026810Z",
          "iopub.execute_input": "2022-04-03T14:45:13.027061Z",
          "iopub.status.idle": "2022-04-03T14:45:21.577879Z",
          "shell.execute_reply.started": "2022-04-03T14:45:13.027024Z",
          "shell.execute_reply": "2022-04-03T14:45:21.577070Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting varname\n  Downloading varname-0.8.3-py3-none-any.whl (21 kB)\nCollecting executing<0.9.0,>=0.8.3\n  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\nCollecting pure_eval<1.0.0\n  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\nCollecting asttokens<3.0.0,>=2.0.0\n  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from asttokens<3.0.0,>=2.0.0->varname) (1.16.0)\nInstalling collected packages: pure-eval, executing, asttokens, varname\nSuccessfully installed asttokens-2.0.5 executing-0.8.3 pure-eval-0.2.2 varname-0.8.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "#%load_ext tensorboard\n",
        "# Reload TensorBoard\n",
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "8p3Tbx8cWEFA",
        "execution": {
          "iopub.status.busy": "2022-04-02T04:50:09.89378Z",
          "iopub.execute_input": "2022-04-02T04:50:09.894039Z",
          "iopub.status.idle": "2022-04-02T04:50:09.899922Z",
          "shell.execute_reply.started": "2022-04-02T04:50:09.894012Z",
          "shell.execute_reply": "2022-04-02T04:50:09.89899Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt\n",
        "from varname import argname\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import zipfile\n",
        "import contractions"
      ],
      "metadata": {
        "id": "mVtYvbbIWRkV",
        "execution": {
          "iopub.status.busy": "2022-04-03T15:01:16.913677Z",
          "iopub.execute_input": "2022-04-03T15:01:16.914028Z",
          "iopub.status.idle": "2022-04-03T15:01:16.919726Z",
          "shell.execute_reply.started": "2022-04-03T15:01:16.913994Z",
          "shell.execute_reply": "2022-04-03T15:01:16.918870Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data\n",
        "\n",
        "<br>Text data is obtained from <a href=\"https://www.gutenberg.org/\">Project Gutenberg</a>. This notebook closely follows tutorial by Machine Learning Mastery (Ref [2]).\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "References:\n",
        "<br>[1] <a href=\"https://www.gutenberg.org/ebooks/16\"> Peter Pan by J. M. Barrie</a>\n",
        "<br>[2] <a href=\"https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\">LSTM Text generation tutorial</a>"
      ],
      "metadata": {
        "id": "eO9AU8NE03B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Peter Pan from Project Gutenberg Ref[1]\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://www.gutenberg.org/files/16/16-0.zip\" \\\n",
        "    -O \"/peterpan.zip\""
      ],
      "metadata": {
        "id": "W4HfFuB9FU1W",
        "outputId": "10a340f9-1829-4c9b-d065-d52e505aa779",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:27.281455Z",
          "iopub.execute_input": "2022-04-03T14:45:27.281698Z",
          "iopub.status.idle": "2022-04-03T14:45:28.597330Z",
          "shell.execute_reply.started": "2022-04-03T14:45:27.281664Z",
          "shell.execute_reply": "2022-04-03T14:45:28.596548Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2022-04-03 14:45:27--  https://www.gutenberg.org/files/16/16-0.zip\nResolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\nConnecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 107629 (105K) [application/zip]\nSaving to: ‘/peterpan.zip’\n\n/peterpan.zip       100%[===================>] 105.11K   517KB/s    in 0.2s    \n\n2022-04-03 14:45:28 (517 KB/s) - ‘/peterpan.zip’ saved [107629/107629]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract dataset to current session\n",
        "zip_ref = zipfile.ZipFile('/peterpan.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "uBAM3A6AFyIM",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.600560Z",
          "iopub.execute_input": "2022-04-03T14:45:28.600781Z",
          "iopub.status.idle": "2022-04-03T14:45:28.611341Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.600755Z",
          "shell.execute_reply": "2022-04-03T14:45:28.610656Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data\n",
        "\n",
        "\n",
        "\n",
        "1.   Clean data.\n",
        "     - Delete unwanted text from data (eg. table of contents etc).\n",
        "     - Remove special characters `. , ! ?`.\n",
        "     - Convert contractions (eg. I've -> I have).\n",
        "2.   Create mapping of unique characters to integers.\n",
        "3.   Split processed data into input `X` and output `y` data.\n",
        "4.   Reshape input data into `[samples, time steps, features]`.\n",
        "5.   Feature normalization.\n",
        "\n"
      ],
      "metadata": {
        "id": "U-2siERmNP3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clean data"
      ],
      "metadata": {
        "id": "_PjXFSn5T61p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/16-0.txt\""
      ],
      "metadata": {
        "id": "7FO_4L3nUFG8",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.612873Z",
          "iopub.execute_input": "2022-04-03T14:45:28.613148Z",
          "iopub.status.idle": "2022-04-03T14:45:28.619175Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.613115Z",
          "shell.execute_reply": "2022-04-03T14:45:28.618368Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get line number at which the story actually starts and ends\n",
        "for n, line in enumerate(open(filename)):\n",
        "    if 'Chapter I.\\n' in line:\n",
        "      startl = n + 1\n",
        "      print('Start at Line', startl)\n",
        "    if 'THE END\\n' in line:\n",
        "      endl = n + 1\n",
        "      print('End at Line', endl)\n"
      ],
      "metadata": {
        "id": "2OsszYNjLzV5",
        "outputId": "8d390284-8e17-4b83-ef88-5b63370a20e2",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.620632Z",
          "iopub.execute_input": "2022-04-03T14:45:28.620961Z",
          "iopub.status.idle": "2022-04-03T14:45:28.637015Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.620927Z",
          "shell.execute_reply": "2022-04-03T14:45:28.636096Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Start at Line 66\nEnd at Line 6288\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rewrite the file to only include line from start line to 1 line before end line\n",
        "with open(filename, 'r+') as f:\n",
        "    lines = f.readlines()\n",
        "    # move file pointer to the beginning of a file\n",
        "    f.seek(0)\n",
        "    # truncate the file\n",
        "    f.truncate()\n",
        "\n",
        "    # start writing lines except the first line\n",
        "    # lines[1:] from line 2 to last line\n",
        "    f.writelines(lines[startl:endl])"
      ],
      "metadata": {
        "id": "W4zRsKtYRWYX",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.638438Z",
          "iopub.execute_input": "2022-04-03T14:45:28.638896Z",
          "iopub.status.idle": "2022-04-03T14:45:28.655810Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.638859Z",
          "shell.execute_reply": "2022-04-03T14:45:28.655197Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if unwanted texts are properly deleted\n",
        "for n, line in enumerate(open(filename)):\n",
        "    if 'The Project Gutenberg eBook of Peter Pan, by James M. Barrie' in line:\n",
        "      print('Oh no! Please check!')\n",
        "    if 'Section 1. General Terms of Use' in line:\n",
        "      print('Oh no! Please check!')"
      ],
      "metadata": {
        "id": "JMnbGawPSNE0",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.657303Z",
          "iopub.execute_input": "2022-04-03T14:45:28.657751Z",
          "iopub.status.idle": "2022-04-03T14:45:28.666727Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.657716Z",
          "shell.execute_reply": "2022-04-03T14:45:28.665930Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the book into memory\n",
        "raw_txt = open(filename, 'r', encoding='utf-8').read()\n",
        "# Convert all to lowercase\n",
        "raw_txt = raw_txt.lower()"
      ],
      "metadata": {
        "id": "5vF8FUoDT3i9",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.670302Z",
          "iopub.execute_input": "2022-04-03T14:45:28.670549Z",
          "iopub.status.idle": "2022-04-03T14:45:28.677287Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.670516Z",
          "shell.execute_reply": "2022-04-03T14:45:28.676158Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix contractions\n",
        "raw_txt = contractions.fix(raw_txt)\n",
        "\n",
        "# Examining the change\n",
        "print(raw_txt[2500:3300])"
      ],
      "metadata": {
        "id": "y_Fyb9hwZek3",
        "outputId": "e45ba37b-db9f-4596-e526-aa3866d5c94a",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.706196Z",
          "iopub.execute_input": "2022-04-03T14:45:28.706546Z",
          "iopub.status.idle": "2022-04-03T14:45:28.728779Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.706511Z",
          "shell.execute_reply": "2022-04-03T14:45:28.728037Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "mrs. darling’s bed, holding her hand and calculating expenses,\nwhile she looked at him imploringly. she wanted to risk it, come what\nmight, but that was not his way; his way was with a pencil and a piece\nof paper, and if she confused him with suggestions he had to begin at\nthe beginning again.\n\n“now do not interrupt,” he would beg of her.\n\n“i have one pound seventeen here, and two and six at the office; i can\ncut off my coffee at the office, say ten shillings, making two nine and\nsix, with your eighteen and three makes three nine seven, with five\nnaught naught in my cheque-book makes eight nine seven—who is that\nmoving?—eight nine seven, dot and carry seven—do not speak, my own—and\nthe pound you lent to that man who came to the door—quiet, child—dot\nand carry child—there, you have done it!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all special characters and stripped white spaces\n",
        "raw_txt = ' '.join([re.sub(r\"[^a-zA-Z0-9]+\", ' ', l).strip() for l in raw_txt.split(\"\\n\")])\n",
        "\n",
        "# Examining the change\n",
        "print(raw_txt[2500:3300])"
      ],
      "metadata": {
        "id": "vfZx_2R5VOAK",
        "outputId": "0ef494d1-45f2-460b-acb9-384876d3bcf9",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.729775Z",
          "iopub.execute_input": "2022-04-03T14:45:28.730187Z",
          "iopub.status.idle": "2022-04-03T14:45:28.770575Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.730147Z",
          "shell.execute_reply": "2022-04-03T14:45:28.769914Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": " looked at him imploringly she wanted to risk it come what might but that was not his way his way was with a pencil and a piece of paper and if she confused him with suggestions he had to begin at the beginning again  now do not interrupt he would beg of her  i have one pound seventeen here and two and six at the office i can cut off my coffee at the office say ten shillings making two nine and six with your eighteen and three makes three nine seven with five naught naught in my cheque book makes eight nine seven who is that moving eight nine seven dot and carry seven do not speak my own and the pound you lent to that man who came to the door quiet child dot and carry child there you have done it did i say nine nine seven yes i said nine nine seven the question is can we try it for a year \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unique character mapping"
      ],
      "metadata": {
        "id": "9msdVS3iczy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sorted list of unique characters\n",
        "chars = sorted(list(set(raw_txt)))\n",
        "# Create dictionary to store unique character to int pair\n",
        "char_to_int = {}\n",
        "for i,v in enumerate(chars):\n",
        "  char_to_int[v] = i\n",
        "\n",
        "# Examining the dictionary\n",
        "print(char_to_int)"
      ],
      "metadata": {
        "id": "q7JA_VJxa8n9",
        "outputId": "08ed78e0-5e16-4778-d902-27ca8bfd9877",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.771522Z",
          "iopub.execute_input": "2022-04-03T14:45:28.772836Z",
          "iopub.status.idle": "2022-04-03T14:45:28.781068Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.772799Z",
          "shell.execute_reply": "2022-04-03T14:45:28.780351Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{' ': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '6': 6, '7': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'f': 13, 'g': 14, 'h': 15, 'i': 16, 'j': 17, 'k': 18, 'l': 19, 'm': 20, 'n': 21, 'o': 22, 'p': 23, 'q': 24, 'r': 25, 's': 26, 't': 27, 'u': 28, 'v': 29, 'w': 30, 'x': 31, 'y': 32, 'z': 33}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_chars = len(raw_txt)\n",
        "total_unique_chars = len(chars)\n",
        "print(\"Total characters in the whole book: \", total_chars)\n",
        "print(\"Total unique characters: \", total_unique_chars)"
      ],
      "metadata": {
        "id": "ti2iXOdycCVz",
        "outputId": "5c0ab7a6-4096-4a26-b69c-414e1dca1863",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:28.782345Z",
          "iopub.execute_input": "2022-04-03T14:45:28.782655Z",
          "iopub.status.idle": "2022-04-03T14:45:28.791537Z",
          "shell.execute_reply.started": "2022-04-03T14:45:28.782622Z",
          "shell.execute_reply": "2022-04-03T14:45:28.790870Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Total characters in the whole book:  244253\nTotal unique characters:  34\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Input/ Output split\n",
        "\n",
        "\n",
        "- `seq_length` determine how the data will be split. Essentially, the length of every subsequence.\n",
        "- Each training set will comprise of *n* time steps of 1 character input `X` followed by 1 character output `y`.\n",
        "- For example, if the sequence length is 4, then the training pattern would be:\n",
        "    <br>`Input -> Output`\n",
        "    <br>` SUND -> A`\n",
        "    <br>` UNDA -> Y`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W4UK9GYLdAKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 200\n",
        "data_X = []\n",
        "data_y = []\n",
        "\n",
        "for i in range(0, total_chars - seq_length, 1):\n",
        "    seq_in = raw_txt[i : i+seq_length] # slice for every 200 characters for each split starting from i\n",
        "    seq_out = raw_txt[i+seq_length] # the next character after seq_in\n",
        "    \n",
        "    for char in seq_in:\n",
        "        data_X.append(char_to_int[char]) # get the int value of each character and append to X\n",
        "        \n",
        "    data_y.append(char_to_int[seq_out]) # append the only character in seq_out"
      ],
      "metadata": {
        "id": "cdz6hC55dP5C",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:53:09.785490Z",
          "iopub.execute_input": "2022-04-03T14:53:09.785768Z",
          "iopub.status.idle": "2022-04-03T14:53:17.494401Z",
          "shell.execute_reply.started": "2022-04-03T14:53:09.785736Z",
          "shell.execute_reply": "2022-04-03T14:53:17.493552Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_patterns = len(data_X)\n",
        "print('Total patterns:', total_patterns)"
      ],
      "metadata": {
        "id": "n5hc6rrjBhqU",
        "outputId": "43bee995-ae8d-4ae1-95e9-50af48c02ce7",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:53:19.226557Z",
          "iopub.execute_input": "2022-04-03T14:53:19.226811Z",
          "iopub.status.idle": "2022-04-03T14:53:19.231821Z",
          "shell.execute_reply.started": "2022-04-03T14:53:19.226782Z",
          "shell.execute_reply": "2022-04-03T14:53:19.231129Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Total patterns: 48810600\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reshape into `[samples, time steps, features]`\n",
        "\n",
        "- samples = number of patterns we have (here we use `-1` to let numpy infer the number of rows)\n",
        "- time steps = number of sequence length per split\n",
        "- features = 1 dimension feature (to produce a 2D array)"
      ],
      "metadata": {
        "id": "U5jG5Ob-KMfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.reshape(data_X, (-1, seq_length, 1)).astype(np.float32)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "tkoTjGkDKVQO",
        "outputId": "f3a1d9d9-cf34-4cfc-cff8-226b52cc00d3",
        "execution": {
          "iopub.status.busy": "2022-04-03T15:34:56.525838Z",
          "iopub.execute_input": "2022-04-03T15:34:56.526562Z",
          "iopub.status.idle": "2022-04-03T15:35:02.754089Z",
          "shell.execute_reply.started": "2022-04-03T15:34:56.526519Z",
          "shell.execute_reply": "2022-04-03T15:35:02.753320Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(244053, 200, 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalization\n",
        "\n",
        "- Rescale the integers to the range 0 to 1.\n",
        "- One-hot encode the output variable to configure the network to predict the probability of the output being each of the 34 unique characters previously identified.\n",
        "- That is, each `y` vlaue is converted into a sparse vactor with a length of 23, full of zeros except with a 1 in the column for the predicted letter."
      ],
      "metadata": {
        "id": "xDxy2ISIYi3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "X = X / float(total_unique_chars)\n",
        "\n",
        "# One hot encode the output variable\n",
        "y = np_utils.to_categorical(data_y).astype(np.float32)"
      ],
      "metadata": {
        "id": "FDIa9s_nZYRL",
        "execution": {
          "iopub.status.busy": "2022-04-03T15:34:52.165953Z",
          "iopub.execute_input": "2022-04-03T15:34:52.166218Z",
          "iopub.status.idle": "2022-04-03T15:34:52.335524Z",
          "shell.execute_reply.started": "2022-04-03T15:34:52.166188Z",
          "shell.execute_reply": "2022-04-03T15:34:52.334758Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "\n",
        "Simple LSTM architecture: **3** stacked LSTM Layers with 0.1 Dropout."
      ],
      "metadata": {
        "id": "IsTtum3B0psN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN Model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                                tf.keras.layers.LSTM(255, input_shape=(X.shape[1], X.shape[2]), return_sequences=True),\n",
        "                                tf.keras.layers.LSTM(255, return_sequences=True),\n",
        "                                tf.keras.layers.LSTM(255, dropout=0.1),\n",
        "                                tf.keras.layers.Dense(y.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ep_Frc4fEKqS",
        "outputId": "ef778802-f994-494c-d66e-71f6255f95dc",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:43.837693Z",
          "iopub.execute_input": "2022-04-03T14:45:43.837953Z",
          "iopub.status.idle": "2022-04-03T14:45:47.237777Z",
          "shell.execute_reply.started": "2022-04-03T14:45:43.837915Z",
          "shell.execute_reply": "2022-04-03T14:45:47.236297Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2022-04-03 14:45:44.246153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:44.338867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:44.339621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:44.340807: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-03 14:45:44.341933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:44.342663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:44.343273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:46.194144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:46.194954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:46.195620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-03 14:45:46.196191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 200, 255)          262140    \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 200, 255)          521220    \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 255)               521220    \n_________________________________________________________________\ndense (Dense)                (None, 34)                8704      \n=================================================================\nTotal params: 1,313,284\nTrainable params: 1,313,284\nNon-trainable params: 0\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "85v5-iuY1OCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs=100):\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    # Initialize tensorboard\n",
        "    logdir = os.path.join(\"logs\", argname('model'))\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "    \n",
        "    # Initialize earlystopping\n",
        "    earlystop_callback = tf.keras.callbacks.EarlyStopping(patience=1, verbose=0, monitor='accuracy', restore_best_weights=True)\n",
        "    \n",
        "    # Initialize checkpoint\n",
        "    filepath = os.path.join(\"checkpoint\", \"weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5\")\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    return model.fit(X, y, epochs=epochs, batch_size=128, callbacks=[tensorboard_callback, checkpoint_callback, earlystop_callback])\n",
        "\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"auccuracy\"])\n",
        "    plt.title(f\"{argname('hist')[:-8]} performance\")\n",
        "    plt.ylabel(\"area_under_curve\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train accuracy\"], loc=\"upper left\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "R8_RjJZw01Lq",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:51.266924Z",
          "iopub.execute_input": "2022-04-03T14:45:51.267596Z",
          "iopub.status.idle": "2022-04-03T14:45:51.277004Z",
          "shell.execute_reply.started": "2022-04-03T14:45:51.267557Z",
          "shell.execute_reply": "2022-04-03T14:45:51.276312Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model)"
      ],
      "metadata": {
        "id": "CY9GXDtFbAlm",
        "execution": {
          "iopub.status.busy": "2022-04-03T12:10:41.340888Z",
          "iopub.execute_input": "2022-04-03T12:10:41.341294Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observe model on TensorBoard"
      ],
      "metadata": {
        "id": "Rc90YYjqcKUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "mZtjNgHk7zcN",
        "execution": {
          "iopub.status.busy": "2022-04-01T23:59:12.569037Z",
          "iopub.execute_input": "2022-04-01T23:59:12.569291Z",
          "iopub.status.idle": "2022-04-01T23:59:17.649547Z",
          "shell.execute_reply.started": "2022-04-01T23:59:12.569263Z",
          "shell.execute_reply": "2022-04-01T23:59:17.648606Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "\n",
        "1.   Trained for a total of 49 epochs until accuracy stops improving.\n",
        "2.   Best accuracy obtained is 71%.\n",
        "\n",
        "Note: Due to *choppy* training time, model training was done in stages."
      ],
      "metadata": {
        "id": "kfsUzsKFn1hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy Model!\n",
        "\n",
        "View the text generated by the trained model."
      ],
      "metadata": {
        "id": "39cypVYxrs4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "start_seq = np.random.randint(0, len(data_X)-1)\n",
        "pattern = data_X[start_seq : start_seq+seq_length]\n",
        "print('Seed:')\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "\n",
        "# generate 1000 characters\n",
        "for i in range (1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x/ float(total_unique_chars)\n",
        "    pred = model.predict(x, verbose=0)\n",
        "    rand = pred[np.random.choice(pred.shape[0], 1, replace=False), :]\n",
        "    index = np.argmax(rand)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print('\\nEnd of prediction')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-03T15:43:02.554571Z",
          "iopub.execute_input": "2022-04-03T15:43:02.555435Z",
          "iopub.status.idle": "2022-04-03T15:43:52.288952Z",
          "shell.execute_reply.started": "2022-04-03T15:43:02.555390Z",
          "shell.execute_reply": "2022-04-03T15:43:52.288218Z"
        },
        "trusted": true,
        "id": "ATZfFLCRHsBD",
        "outputId": "fb019f65-14e8-44b8-c1f2-d88fae79fb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Seed:\n\" ide and sometimes winning and when it won peter always sympathetic to the weaker side could not help clapping it was such a gallant piece of paper  it was not really a piece for it was fighting the ti \"\nme the children are all the boys were all but i will tell you  we could go the most beautiful father went again in the plank to wendy he said the pirates started on the water that the boys were grown up the last time they were all on the rock wendy s fault  she was frightfully ashameep the gaiety of the bed post and then at last he stood on the rock and she saw that the boys were grown up the last time they were all on the rock wendy s fault  she was frightfully ashameep the gaiety of the bed post and then at last he stood on the rock and she saw that the boys were grown up the last time they were all on the rock wendy s fault  she was frightfully ashameep the gaiety of the bed post and then at last he stood on the rock and she saw that the boys were grown up the last time they were all on the rock wendy s fault  she was frightfully ashameep the gaiety of the bed post and then at last he stood on the rock and she saw that the boys were grown up the last time they were all on the rock w\nEnd of prediction\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "LeyABosu2dFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('../input/peterpan-model-71/weights-improvement-14-0.71.hdf5')\n",
        "\n",
        "# Check its architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Xo_EWquv2eti",
        "outputId": "ec74f9f0-c7ff-46ba-946c-03ea04e90cc6",
        "execution": {
          "iopub.status.busy": "2022-04-03T14:45:56.659856Z",
          "iopub.execute_input": "2022-04-03T14:45:56.660112Z",
          "iopub.status.idle": "2022-04-03T14:45:57.604569Z",
          "shell.execute_reply.started": "2022-04-03T14:45:56.660082Z",
          "shell.execute_reply": "2022-04-03T14:45:57.603803Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 200, 255)          262140    \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 200, 255)          521220    \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 255)               521220    \n_________________________________________________________________\ndense (Dense)                (None, 34)                8704      \n=================================================================\nTotal params: 1,313,284\nTrainable params: 1,313,284\nNon-trainable params: 0\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard import notebook\n",
        "notebook.list() # View open TensorBoard instances\n",
        "# notebook.display(port=6006, height=5000)"
      ],
      "metadata": {
        "id": "KBHp6M_zgjp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}