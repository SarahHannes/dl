{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intent-classification-lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**INTENT CLASSIFICATION WITH LSTM**\n",
        "\n",
        "This notebook aims to classify intents from text input into 4 categories `[BookRestaurant, GetWeather, PlayMusic, RateBook]`. In order for chatbot  to be able to give appropriate response, it needs to first correctly classify user intends. Therefore, intent classification model usually implemented as the first stacked model in most of all chatbot model.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "f7Df7-I3sMTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "6sFE1HL0DjJX"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Krc2ucryqA4",
        "outputId": "40e10ff9-eaa8-49e7-8e21-4525ea388937"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 26.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.46.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from collections import defaultdict, namedtuple\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout, Dense, Activation, Flatten, Embedding"
      ],
      "metadata": {
        "id": "b8QpJogFquuz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8E8Snnotj3Q",
        "outputId": "6749c0fc-f136-4087-8edb-6cb4e9f5f7e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "uRAqytuOqbSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw2Itu66qRgf",
        "outputId": "b0a29dfe-a36b-4c54-844c-f64291c2e6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-12 07:18:25--  https://cainvas-static.s3.amazonaws.com/media/user_data/vomchaithany/train.csv\n",
            "Resolving cainvas-static.s3.amazonaws.com (cainvas-static.s3.amazonaws.com)... 52.219.62.44\n",
            "Connecting to cainvas-static.s3.amazonaws.com (cainvas-static.s3.amazonaws.com)|52.219.62.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 441947 (432K) [application/vnd.ms-excel]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>] 431.59K   515KB/s    in 0.8s    \n",
            "\n",
            "2022-06-12 07:18:26 (515 KB/s) - ‘train.csv’ saved [441947/441947]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -N https://cainvas-static.s3.amazonaws.com/media/user_data/vomchaithany/train.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-W5_h8L5qfh8",
        "outputId": "8342cc8e-0894-426d-c012-208e7bf907ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence  BookRestaurant  \\\n",
              "0        book The Middle East restaurant in IN for noon               1   \n",
              "1         Book a table at T-Rex distant from Halsey St.               1   \n",
              "2     I'd like to eat at a taverna that serves chili...               1   \n",
              "3     I have a party of four in Japan and need a res...               1   \n",
              "4     Please make a restaurant reservation for somew...               1   \n",
              "...                                                 ...             ...   \n",
              "7924                         rate this textbook 0 stars               0   \n",
              "7925               give 5 out of 6 stars to Coming Home               0   \n",
              "7926  Give Drift: The Unmooring of American Military...               0   \n",
              "7927         give 1 out of 6 points to Revolution World               0   \n",
              "7928                Rate this essay zero stars out of 6               0   \n",
              "\n",
              "      GetWeather  PlayMusic  RateBook  \n",
              "0              0          0         0  \n",
              "1              0          0         0  \n",
              "2              0          0         0  \n",
              "3              0          0         0  \n",
              "4              0          0         0  \n",
              "...          ...        ...       ...  \n",
              "7924           0          0         1  \n",
              "7925           0          0         1  \n",
              "7926           0          0         1  \n",
              "7927           0          0         1  \n",
              "7928           0          0         1  \n",
              "\n",
              "[7929 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df1a3a5e-c19c-40ba-9328-91601742c6f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>BookRestaurant</th>\n",
              "      <th>GetWeather</th>\n",
              "      <th>PlayMusic</th>\n",
              "      <th>RateBook</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>book The Middle East restaurant in IN for noon</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Book a table at T-Rex distant from Halsey St.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'd like to eat at a taverna that serves chili...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have a party of four in Japan and need a res...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please make a restaurant reservation for somew...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7924</th>\n",
              "      <td>rate this textbook 0 stars</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7925</th>\n",
              "      <td>give 5 out of 6 stars to Coming Home</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7926</th>\n",
              "      <td>Give Drift: The Unmooring of American Military...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7927</th>\n",
              "      <td>give 1 out of 6 points to Revolution World</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7928</th>\n",
              "      <td>Rate this essay zero stars out of 6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7929 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df1a3a5e-c19c-40ba-9328-91601742c6f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df1a3a5e-c19c-40ba-9328-91601742c6f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df1a3a5e-c19c-40ba-9328-91601742c6f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "As we can observe, the objective of this notebook is to classify sentence into 4 categories `[BookRestaurant, GetWeather, PlayMusic, RateBook]`. The data is already one-hot-encoded into its respective classes, so we only need to do preprocessing on the input sentence. As such the preprocessing steps that we will do are:\n",
        "\n",
        "- Stopwords removal\n",
        "- Lemmatization (eg teaches -> teach)\n",
        "- Stemming (eg sailed -> sail)\n",
        "- Vectorization (maps text features to integer sequences)"
      ],
      "metadata": {
        "id": "BQAJ9EhprqfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopword(text):\n",
        "    \"\"\"\n",
        "    input: string\n",
        "    Remove stopwords.\n",
        "    return: string without stopwords    \n",
        "    \"\"\"\n",
        "    filtered = []\n",
        "    #stopword = set(stopwords.words('english'))\n",
        "    # for every word in text, append it to filtered list if the word is not in stopword set\n",
        "    for word in text.split(' '):\n",
        "        if word not in stopword:\n",
        "            filtered.append(word)\n",
        "    return ' '.join(filtered)\n",
        "\n",
        "def get_lemma(text):\n",
        "    \"\"\"\n",
        "    input: string\n",
        "    lemmatizes words. (eg teaches -> teach)\n",
        "    output: string\n",
        "    \"\"\"\n",
        "    t = []\n",
        "    #wnl = WordNetLemmatizer()\n",
        "    for word in text.split(' '):\n",
        "        t.append(wnl.lemmatize(word))\n",
        "    return \" \".join(t)\n",
        "\n",
        "def get_stem(text):\n",
        "    \"\"\"\n",
        "    input: string\n",
        "    return word stem using SnowballStemmer, ignore stopwords. (eg sailed -> sail)\n",
        "    return: string\n",
        "    \"\"\"\n",
        "    t = []\n",
        "    #stemmer = SnowballStemmer('english', ignore_stopwords = True)\n",
        "    for word in text.split(' '):\n",
        "        t.append(stemmer.stem(word))\n",
        "    return \" \".join(t)\n",
        "\n",
        "def normalize(text, is_lemma=False, is_stem=False, no_stopword=False):\n",
        "  \"\"\"\n",
        "    input: string\n",
        "    clean text (normalize, lowercase, remove digits, add space around punctuations, strip whitespace) then perform lemmatization, stemming or stopwords removal as per user specification.\n",
        "    return: string\n",
        "  \"\"\"\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  string_text = text.numpy().decode(\"utf-8\")  # converts tf.constant() type to byte, then decode into string\n",
        "  if is_stem:\n",
        "    return get_stem(string_text)\n",
        "  if is_lemma:\n",
        "    return get_lemma(string_text)\n",
        "  if no_stopword:\n",
        "    return remove_stopword(string_text)\n",
        "  return string_text\n",
        "\n",
        "def tf_add_start_end(text):\n",
        "  \"\"\"\n",
        "  input: tensorflow.python.framework.ops.EagerTensor\n",
        "  Adds [START] and [END] tag to text. For encoder-decoder model.\n",
        "  return: tensorflow.python.framework.ops.EagerTensor\n",
        "  \"\"\"\n",
        "  return tf.strings.join(['[START]', text, '[END]'], separator=' ')"
      ],
      "metadata": {
        "id": "gDQ_pSitrI_P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Normalization"
      ],
      "metadata": {
        "id": "QeUgDy-1JTCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing\n",
        "stemmer = SnowballStemmer('english', ignore_stopwords = True)\n",
        "wnl = WordNetLemmatizer()\n",
        "stopword = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "PgEow7U5tOO-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization output with original text for comparison\n",
        "# \"%-xxs\" gives size requirement '-' for left justification (pretty printing purposes) ref: https://stackoverflow.com/questions/12684368/how-to-left-align-a-fixed-width-string\n",
        "\n",
        "example_text = tf.constant(\"I have a party of four in Japan and I'd like to make a reservation at Rimsky-Korsakoffee House on Aug. the 3rd.\")\n",
        "print(\"%-32s %-100s\" % (\"Original Text:\", example_text.numpy().decode()))\n",
        "print(\"%-32s %-100s\" % (\"Normalized :\", normalize(example_text)))\n",
        "print(\"%-32s %-100s\" % (\"Normalized + Lemmatized :\", normalize(example_text, is_lemma=True)))\n",
        "print(\"%-32s %-100s\" % (\"Normalized + Stemmed :\", normalize(example_text, is_stem=True)))\n",
        "print(\"%-32s %-100s\" % (\"Normalized + Stopwords Removal :\", normalize(example_text, no_stopword=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWIpK_5Q3cBS",
        "outputId": "a665e713-ea9c-4e49-e940-6b804d6be2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:                   I have a party of four in Japan and I'd like to make a reservation at Rimsky-Korsakoffee House on Aug. the 3rd.\n",
            "Normalized :                     i have a party of four in japan and id like to make a reservation at rimskykorsakoffee house on aug .  the rd .\n",
            "Normalized + Lemmatized :        i have a party of four in japan and id like to make a reservation at rimskykorsakoffee house on aug .  the rd .\n",
            "Normalized + Stemmed :           i have a parti of four in japan and id like to make a reserv at rimskykorsakoffe hous on aug .  the rd .\n",
            "Normalized + Stopwords Removal : party four japan id like make reservation rimskykorsakoffee house aug .  rd .                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "\n",
        "df['norm'] = df['sentence'].apply(lambda x: normalize(x))\n",
        "df['norm_lemma'] = df['sentence'].apply(lambda x: normalize(x, is_lemma=True))\n",
        "df['norm_stem'] = df['sentence'].apply(lambda x: normalize(x, is_stem=True))\n",
        "df['norm_stop'] = df['sentence'].apply(lambda x: normalize(x, no_stopword=True))"
      ],
      "metadata": {
        "id": "Iw4HiiCWE9TW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "zhEISThfFbuu",
        "outputId": "870f5d8c-7b5f-4045-e2bc-407600400742"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  BookRestaurant  \\\n",
              "0     book The Middle East restaurant in IN for noon               1   \n",
              "1      Book a table at T-Rex distant from Halsey St.               1   \n",
              "2  I'd like to eat at a taverna that serves chili...               1   \n",
              "3  I have a party of four in Japan and need a res...               1   \n",
              "4  Please make a restaurant reservation for somew...               1   \n",
              "\n",
              "   GetWeather  PlayMusic  RateBook  \\\n",
              "0           0          0         0   \n",
              "1           0          0         0   \n",
              "2           0          0         0   \n",
              "3           0          0         0   \n",
              "4           0          0         0   \n",
              "\n",
              "                                                norm  \\\n",
              "0     book the middle east restaurant in in for noon   \n",
              "1      book a table at trex distant from halsey st .   \n",
              "2  id like to eat at a taverna that serves chili ...   \n",
              "3  i have a party of four in japan and need a res...   \n",
              "4  please make a restaurant reservation for somew...   \n",
              "\n",
              "                                          norm_lemma  \\\n",
              "0     book the middle east restaurant in in for noon   \n",
              "1      book a table at trex distant from halsey st .   \n",
              "2  id like to eat at a taverna that serf chili co...   \n",
              "3  i have a party of four in japan and need a res...   \n",
              "4  please make a restaurant reservation for somew...   \n",
              "\n",
              "                                           norm_stem  \\\n",
              "0         book the middl east restaur in in for noon   \n",
              "1       book a tabl at trex distant from halsey st .   \n",
              "2  id like to eat at a taverna that serv chili co...   \n",
              "3  i have a parti of four in japan and need a res...   \n",
              "4  pleas make a restaur reserv for somewher in mo...   \n",
              "\n",
              "                                           norm_stop  \n",
              "0                   book middle east restaurant noon  \n",
              "1                book table trex distant halsey st .  \n",
              "2   id like eat taverna serves chili con carne party  \n",
              "3  party four japan need reservation rimskykorsak...  \n",
              "4  please make restaurant reservation somewhere m...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12b22f32-3827-4f80-9956-8dba0f5a1dbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>BookRestaurant</th>\n",
              "      <th>GetWeather</th>\n",
              "      <th>PlayMusic</th>\n",
              "      <th>RateBook</th>\n",
              "      <th>norm</th>\n",
              "      <th>norm_lemma</th>\n",
              "      <th>norm_stem</th>\n",
              "      <th>norm_stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>book The Middle East restaurant in IN for noon</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>book the middle east restaurant in in for noon</td>\n",
              "      <td>book the middle east restaurant in in for noon</td>\n",
              "      <td>book the middl east restaur in in for noon</td>\n",
              "      <td>book middle east restaurant noon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Book a table at T-Rex distant from Halsey St.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>book a table at trex distant from halsey st .</td>\n",
              "      <td>book a table at trex distant from halsey st .</td>\n",
              "      <td>book a tabl at trex distant from halsey st .</td>\n",
              "      <td>book table trex distant halsey st .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'd like to eat at a taverna that serves chili...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>id like to eat at a taverna that serves chili ...</td>\n",
              "      <td>id like to eat at a taverna that serf chili co...</td>\n",
              "      <td>id like to eat at a taverna that serv chili co...</td>\n",
              "      <td>id like eat taverna serves chili con carne party</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have a party of four in Japan and need a res...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>i have a party of four in japan and need a res...</td>\n",
              "      <td>i have a party of four in japan and need a res...</td>\n",
              "      <td>i have a parti of four in japan and need a res...</td>\n",
              "      <td>party four japan need reservation rimskykorsak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please make a restaurant reservation for somew...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>please make a restaurant reservation for somew...</td>\n",
              "      <td>please make a restaurant reservation for somew...</td>\n",
              "      <td>pleas make a restaur reserv for somewher in mo...</td>\n",
              "      <td>please make restaurant reservation somewhere m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12b22f32-3827-4f80-9956-8dba0f5a1dbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12b22f32-3827-4f80-9956-8dba0f5a1dbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12b22f32-3827-4f80-9956-8dba0f5a1dbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split into Train/ Validation sets\n",
        "\n",
        "We are interested in finding out the preprocessing technique which will produce model with high accuracy. Therefore, we will split the inputs preprocessed with 4 different preprocessing techniques (+ 1 with original input) as one training set each.\n",
        "\n",
        "1. `ori` : Training set with original input\n",
        "2. `norm` : Training set with normalized input\n",
        "3. `norm_lemma` : Training set with normalized + lemmatized input\n",
        "4. `norm_stem` : Training set with normalized + stemmed input\n",
        "5. `norm_stopword` : Training set with normalized + stopwords removal input"
      ],
      "metadata": {
        "id": "RUxa9N2FEvi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Original input\n",
        "X = df['sentence']\n",
        "y = df[['BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook']]\n",
        "\n",
        "# 2: Normalized input\n",
        "X_n = df['norm']\n",
        "# 3: Normalized + Lemmatized input\n",
        "X_nl = df['norm_lemma']\n",
        "# 4: Normalized + Stemmed input\n",
        "X_ns = df['norm_stem']\n",
        "# 5: Normalized + Stopwords Removal input\n",
        "X_nr = df['norm_stop']"
      ],
      "metadata": {
        "id": "HmwAXobMESvX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in [X, X_n, X_nl, X_ns, X_nr]:\n",
        "  print(t.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iyBGa5bI_EN",
        "outputId": "dd57754a-f335-4758-a8c0-fac1701442ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7929,)\n",
            "(7929,)\n",
            "(7929,)\n",
            "(7929,)\n",
            "(7929,)\n",
            "(7929, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dictionary to save all train/test split sets\n",
        "d_inputs = defaultdict(tuple)\n",
        "\n",
        "# Initialize namedtuple to save train/test sets for easy access\n",
        "Input = namedtuple('Input', 'xtrain xtest ytrain ytest xtrain_padded xtest_padded')"
      ],
      "metadata": {
        "id": "ZVFA66JLT2pY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "# Fit tokenizer on original data\n",
        "tokenizer.fit_on_texts(df['sentence'])\n",
        "tokenizer_vocab_size = len(tokenizer.word_index) + 1\n",
        "print(tokenizer_vocab_size)\n",
        "\n",
        "# Get the max length of sentence in column and add 1000\n",
        "maxlength = df['sentence'].map(len).max() + 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDvEVzJpCRXk",
        "outputId": "453cf721-3fdb-4db0-85b6-33920c4bd75a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization, Encoding, Padding"
      ],
      "metadata": {
        "id": "FcwreNA4Cr6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in [('ori', X), ('norm', X_n), ('norm_lemma', X_nl), ('norm_stem', X_ns), ('norm_stopword', X_nr)]:\n",
        "  # Split preprocessed input text into train/test sets\n",
        "  xtrain, xtest, ytrain, ytest = train_test_split(x[1], y, test_size = 0.2, stratify=y, random_state=0)\n",
        "  \n",
        "  # Tokenize into sequence and encode into numerical\n",
        "  xtrain_encoded = tokenizer.texts_to_sequences(xtrain)\n",
        "  xtest_encoded = tokenizer.texts_to_sequences(xtest)\n",
        "\n",
        "  # Save all in dictionary\n",
        "  d_inputs[x[0]] = Input(xtrain=xtrain, xtest=xtest, ytrain=ytrain, ytest=ytest,\n",
        "                         xtrain_padded=sequence.pad_sequences(xtrain_encoded, maxlen = maxlength),\n",
        "                         xtest_padded=sequence.pad_sequences(xtest_encoded, maxlen = maxlength))\n",
        "\n",
        "  print('Done train test split and inserted into d_inputs for:', x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBSg-IWmMVdH",
        "outputId": "d1bb8b0d-7dd8-4f74-c4f0-83ac577d0743"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done train test split and inserted into d_inputs for: ori\n",
            "Done train test split and inserted into d_inputs for: norm\n",
            "Done train test split and inserted into d_inputs for: norm_lemma\n",
            "Done train test split and inserted into d_inputs for: norm_stem\n",
            "Done train test split and inserted into d_inputs for: norm_stopword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(d_inputs.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiKKIDVUVb11",
        "outputId": "0b9e8850-52b4-4e50-e435-3b1691e9beac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['ori', 'norm', 'norm_lemma', 'norm_stem', 'norm_stopword'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We had successfully split data into train and test sets for each preprocessing techniques applied. We had also saved the split data into defaultdict as named tuple for easy accessing.\n",
        "\n",
        "To access the split data, we provide the preprocessing type (one of `['ori', 'norm', 'norm_lemma', 'norm_stem', 'norm_stopword']`) and use `.` notation to access specific split. The splits names are one of `['xtrain', 'xtest', 'ytrain', 'ytest', 'xtrain_padded', 'xtest_padded']`\n",
        "\n",
        "For example to access train set of normalized input, we use:\n",
        "`d_inputs['norm'].xtrain`"
      ],
      "metadata": {
        "id": "HnNWF_bSV7Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_inputs['ori']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbyjMvf3VyKs",
        "outputId": "eae174e4-4ba6-4542-feb4-3ac16fe9324b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Input(xtrain=1159        I want a table for 2 at a Portugal restaurant\n",
              "327     I need seating for ten people at a bar that se...\n",
              "7895                                I give this book a 5.\n",
              "7361                   rate this essay one out of 6 stars\n",
              "3190    Whats the temperature not far from Valley of Fire\n",
              "                              ...                        \n",
              "5585                        I'd like to hear Helen Baylor\n",
              "789     book The Kegs Drive-In in 37 weeks  in Saudi A...\n",
              "5121                 play the top five songs by Gad Elbaz\n",
              "5006              Can you play music from 2003 on Netflix\n",
              "7309    this album is hot trash, it's totally zero stars.\n",
              "Name: sentence, Length: 6343, dtype: object, xtest=658     Book a tyrolean restaurant in Crocker Indiana ...\n",
              "5003                   I want to hear that tune from 2010\n",
              "1735                              book a restaurant for 8\n",
              "4836                       play Iheart tunes by Neil Finn\n",
              "5458               Play Me Against The World from Glukoza\n",
              "                              ...                        \n",
              "1173    Book a table at a tavern in Albania for annett...\n",
              "6230                          Rate this essay five points\n",
              "7323                     rate I Commitments 5 of 6 points\n",
              "7144                    My Life as a Fake is one out of 6\n",
              "4374       play Top 100 Indie Tracks on Spotify on Lastfm\n",
              "Name: sentence, Length: 1586, dtype: object, ytrain=      BookRestaurant  GetWeather  PlayMusic  RateBook\n",
              "1159               1           0          0         0\n",
              "327                1           0          0         0\n",
              "7895               0           0          0         1\n",
              "7361               0           0          0         1\n",
              "3190               0           1          0         0\n",
              "...              ...         ...        ...       ...\n",
              "5585               0           0          1         0\n",
              "789                1           0          0         0\n",
              "5121               0           0          1         0\n",
              "5006               0           0          1         0\n",
              "7309               0           0          0         1\n",
              "\n",
              "[6343 rows x 4 columns], ytest=      BookRestaurant  GetWeather  PlayMusic  RateBook\n",
              "658                1           0          0         0\n",
              "5003               0           0          1         0\n",
              "1735               1           0          0         0\n",
              "4836               0           0          1         0\n",
              "5458               0           0          1         0\n",
              "...              ...         ...        ...       ...\n",
              "1173               1           0          0         0\n",
              "6230               0           0          0         1\n",
              "7323               0           0          0         1\n",
              "7144               0           0          0         1\n",
              "4374               0           0          1         0\n",
              "\n",
              "[1586 rows x 4 columns], xtrain_padded=array([[   0,    0,    0, ...,    1,  875,   18],\n",
              "       [   0,    0,    0, ...,   58, 1342,  315],\n",
              "       [   0,    0,    0, ...,    7,    1,   50],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   24, 5787, 5788],\n",
              "       [   0,    0,    0, ...,  541,   14,  124],\n",
              "       [   0,    0,    0, ..., 7176,   67,   30]], dtype=int32), xtest_padded=array([[  0,   0,   0, ...,   4,  48,  55],\n",
              "       [  0,   0,   0, ..., 187,  13, 987],\n",
              "       [  0,   0,   0, ...,  18,   4,  97],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   5,  11,  32],\n",
              "       [  0,   0,   0, ...,  23,   5,  11],\n",
              "       [  0,   0,   0, ..., 134,  14, 148]], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\n",
        "\n",
        "We will build simple LSTM model for this intent classification task."
      ],
      "metadata": {
        "id": "Ftj39aeZob9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ori = Sequential([\n",
        "                     Embedding(tokenizer_vocab_size, 32, input_length = maxlength),\n",
        "                     LSTM(100),\n",
        "                     Dropout(0.5),\n",
        "                     Dense(4, activation='softmax') ])\n",
        "\n",
        "model_norm = Sequential([\n",
        "                     Embedding(tokenizer_vocab_size, 32, input_length = maxlength),\n",
        "                     LSTM(100),\n",
        "                     Dropout(0.5),\n",
        "                     Dense(4, activation='softmax') ])\n",
        "\n",
        "model_norm_lemma = Sequential([\n",
        "                     Embedding(tokenizer_vocab_size, 32, input_length = maxlength),\n",
        "                     LSTM(100),\n",
        "                     Dropout(0.5),\n",
        "                     Dense(4, activation='softmax') ])\n",
        "\n",
        "model_norm_stem = Sequential([\n",
        "                     Embedding(tokenizer_vocab_size, 32, input_length = maxlength),\n",
        "                     LSTM(100),\n",
        "                     Dropout(0.5),\n",
        "                     Dense(4, activation='softmax') ])\n",
        "\n",
        "model_norm_stopword = Sequential([\n",
        "                     Embedding(tokenizer_vocab_size, 32, input_length = maxlength),\n",
        "                     LSTM(100),\n",
        "                     Dropout(0.5),\n",
        "                     Dense(4, activation='softmax') ])"
      ],
      "metadata": {
        "id": "SKkXpD2rlOJq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ori.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x53L4n-SqTHu",
        "outputId": "f76d30b0-9859-43dc-8096-7cc68e945f65"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1186, 32)          240704    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 404       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 294,308\n",
            "Trainable params: 294,308\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(preprocess_name, model, xtrain, ytrain, xtest, ytest, epochs=40):\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Initialize tensorboard\n",
        "  logdir = os.path.join(\"logs\", preprocess_name)\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "  filepath = os.path.join(\"checkpoint\", \"weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5\")\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='accuracy', verbose=1, mode='max')\n",
        "\n",
        "  return model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=epochs, callbacks=[tensorboard_callback, earlystop, checkpoint])"
      ],
      "metadata": {
        "id": "WzF8zv2etmFN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist1 = train_model('ori', model_ori, d_inputs['ori'].xtrain_padded, d_inputs['ori'].ytrain, d_inputs['ori'].xtest_padded, d_inputs['ori'].ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_LN7XbODlIT",
        "outputId": "18da795a-d324-4e5b-d9c9-6824470943e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.6669 - accuracy: 0.8072\n",
            "Epoch 1: accuracy improved from -inf to 0.80719, saving model to checkpoint/weights-improvement-01-0.81.hdf5\n",
            "199/199 [==============================] - 12s 51ms/step - loss: 0.6669 - accuracy: 0.8072 - val_loss: 0.0587 - val_accuracy: 0.9931\n",
            "Epoch 2/40\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9951\n",
            "Epoch 2: accuracy improved from 0.80719 to 0.99511, saving model to checkpoint/weights-improvement-02-1.00.hdf5\n",
            "199/199 [==============================] - 9s 46ms/step - loss: 0.0351 - accuracy: 0.9951 - val_loss: 0.0187 - val_accuracy: 0.9968\n",
            "Epoch 2: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist2 = train_model('norm', model_norm, d_inputs['norm'].xtrain_padded, d_inputs['norm'].ytrain, d_inputs['norm'].xtest_padded, d_inputs['norm'].ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MiOyIvxXb09",
        "outputId": "01ae3f46-2eb2-4e7e-d7f8-cc656f60cd00"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.7376 - accuracy: 0.8031\n",
            "Epoch 1: accuracy improved from -inf to 0.80309, saving model to checkpoint/weights-improvement-01-0.80.hdf5\n",
            "199/199 [==============================] - 12s 51ms/step - loss: 0.7376 - accuracy: 0.8031 - val_loss: 0.1686 - val_accuracy: 0.9861\n",
            "Epoch 2/40\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9899\n",
            "Epoch 2: accuracy improved from 0.80309 to 0.98991, saving model to checkpoint/weights-improvement-02-0.99.hdf5\n",
            "199/199 [==============================] - 9s 46ms/step - loss: 0.0883 - accuracy: 0.9899 - val_loss: 0.0407 - val_accuracy: 0.9950\n",
            "Epoch 2: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist3 = train_model('norm_lemma', model_norm_lemma, d_inputs['norm_lemma'].xtrain_padded, d_inputs['norm_lemma'].ytrain, d_inputs['norm_lemma'].xtest_padded, d_inputs['norm_lemma'].ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TeRXyVNYKf3",
        "outputId": "8494bc46-de03-4735-bb68-aa844c3fc7e8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "199/199 [==============================] - ETA: 0s - loss: 1.0427 - accuracy: 0.6845\n",
            "Epoch 1: accuracy improved from -inf to 0.68453, saving model to checkpoint/weights-improvement-01-0.68.hdf5\n",
            "199/199 [==============================] - 12s 51ms/step - loss: 1.0427 - accuracy: 0.6845 - val_loss: 0.3506 - val_accuracy: 0.9685\n",
            "Epoch 2/40\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.1979 - accuracy: 0.9809\n",
            "Epoch 2: accuracy improved from 0.68453 to 0.98092, saving model to checkpoint/weights-improvement-02-0.98.hdf5\n",
            "199/199 [==============================] - 10s 48ms/step - loss: 0.1977 - accuracy: 0.9809 - val_loss: 0.0850 - val_accuracy: 0.9918\n",
            "Epoch 2: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist4 = train_model('norm_stem', model_norm_stem, d_inputs['norm_stem'].xtrain_padded, d_inputs['norm_stem'].ytrain, d_inputs['norm_stem'].xtest_padded, d_inputs['norm_stem'].ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16uDEeeUYoLB",
        "outputId": "b5562414-d4ec-4c1a-aca7-783140bc1723"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9965\n",
            "Epoch 1: accuracy improved from -inf to 0.99653, saving model to checkpoint/weights-improvement-01-1.00.hdf5\n",
            "199/199 [==============================] - 12s 51ms/step - loss: 0.0169 - accuracy: 0.9965 - val_loss: 0.0193 - val_accuracy: 0.9956\n",
            "Epoch 2/40\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9978\n",
            "Epoch 2: accuracy improved from 0.99653 to 0.99779, saving model to checkpoint/weights-improvement-02-1.00.hdf5\n",
            "199/199 [==============================] - 9s 46ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0214 - val_accuracy: 0.9962\n",
            "Epoch 2: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist5 = train_model('norm_stopword', model_norm_stopword, d_inputs['norm_stopword'].xtrain_padded, d_inputs['norm_stopword'].ytrain, d_inputs['norm_stopword'].xtest_padded, d_inputs['norm_stopword'].ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeDG7Xl3YuwM",
        "outputId": "ec1c4d23-51a1-4b55-c1af-9aaefa79aec8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "199/199 [==============================] - ETA: 0s - loss: 1.2676 - accuracy: 0.7118\n",
            "Epoch 1: accuracy improved from -inf to 0.71181, saving model to checkpoint/weights-improvement-01-0.71.hdf5\n",
            "199/199 [==============================] - 12s 53ms/step - loss: 1.2676 - accuracy: 0.7118 - val_loss: 0.4885 - val_accuracy: 0.7907\n",
            "Epoch 2/40\n",
            "198/199 [============================>.] - ETA: 0s - loss: 1.5652 - accuracy: 0.5777\n",
            "Epoch 2: accuracy did not improve from 0.71181\n",
            "199/199 [==============================] - 10s 48ms/step - loss: 1.5641 - accuracy: 0.5781 - val_loss: 0.4465 - val_accuracy: 0.9912\n",
            "Epoch 2: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy Model"
      ],
      "metadata": {
        "id": "dlI8BPgpZT1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['BookRestaurant','GetWeather','PlayMusic','RateBook']"
      ],
      "metadata": {
        "id": "v-pkRgyKbR3F"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\"Play snow patrol's run\", \"get me pumps up kicks and mgmt\", \"give alice in the wonderland a tens\"] \n",
        "\n",
        "for t in sample_texts:\n",
        "  print('Sample text:', t)\n",
        "  tokens = tokenizer.texts_to_sequences([t])\n",
        "  tokens = sequence.pad_sequences(tokens, maxlen = maxlength)\n",
        "  for m in [model_ori, model_norm, model_norm_lemma, model_norm_stem, model_norm_stopword]:\n",
        "    print(classes[model_ori.predict(np.array(tokens)).argmax()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgzFZDUVZWpM",
        "outputId": "b3415989-6533-4c44-eaf2-9e2b93a39164"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample text: Play snow patrol's run\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "Sample text: get me pumps up kicks and mgmt\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "PlayMusic\n",
            "Sample text: give alice in the wonderland a tens\n",
            "RateBook\n",
            "RateBook\n",
            "RateBook\n",
            "RateBook\n",
            "RateBook\n"
          ]
        }
      ]
    }
  ]
}